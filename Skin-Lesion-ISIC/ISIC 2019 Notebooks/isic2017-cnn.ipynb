{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-tuner","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-04T11:51:21.678003Z","iopub.execute_input":"2023-06-04T11:51:21.679000Z","iopub.status.idle":"2023-06-04T11:51:26.121161Z","shell.execute_reply.started":"2023-06-04T11:51:21.678963Z","shell.execute_reply":"2023-06-04T11:51:26.119777Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/site-packages (1.3.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from keras-tuner) (2.31.0)\nRequirement already satisfied: kt-legacy in /usr/local/lib/python3.8/site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from keras-tuner) (23.1)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (2023.5.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras-tuner\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing import image\nfrom kerastuner import RandomSearch","metadata":{"execution":{"iopub.status.busy":"2023-06-04T11:51:28.525306Z","iopub.execute_input":"2023-06-04T11:51:28.526159Z","iopub.status.idle":"2023-06-04T11:51:33.006095Z","shell.execute_reply.started":"2023-06-04T11:51:28.526113Z","shell.execute_reply":"2023-06-04T11:51:33.004782Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/site-packages (1.3.5)\nRequirement already satisfied: kt-legacy in /usr/local/lib/python3.8/site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from keras-tuner) (23.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from keras-tuner) (2.31.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (2023.5.7)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->keras-tuner) (1.26.16)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\n# Load the ground truth data\ntrain_data = pd.read_csv('/kaggle/input/isicgt/ISIC-2017_Training_Part3_GroundTruth.csv')\ntrain_data.head()\n\n# Load the training images\nstore_list = []\nimage_height = 350\nimage_width = 350\nfor i in tqdm(range(train_data.shape[0])):\n    path = '/kaggle/input/isic2019/ISIC-2017_Training_Data/' + train_data['image_id'][i] + '.jpg'\n    image_check = image.load_img(path, target_size=(image_height, image_width))\n    image_check = image.img_to_array(image_check)\n    # scaling the images\n    image_check = image_check/255\n    store_list.append(image_check)\nx_train = np.array(store_list)\ny_train = train_data.drop(columns=['image_id'])\ny_train = y_train.to_numpy()\n\n# Load the test data\ntest_data = pd.read_csv('/kaggle/input/test2017isic/ISIC-2017_Test_v2_Part3_GroundTruth.csv')\ntest_data.head()\n\n# Load the test images\nstore_list = []\nfor i in tqdm(range(test_data.shape[0])):\n    path = '/kaggle/input/test2017isic/ISIC-2017_Test_v2_Data/ISIC-2017_Test_v2_Data/' + test_data['image_id'][i] + '.jpg'\n    image_check = image.load_img(path, target_size=(image_height, image_width))\n    image_check = image.img_to_array(image_check)\n    # scaling the images\n    image_check = image_check/255\n    store_list.append(image_check)\nx_test = np.array(store_list)\ny_test = test_data.drop(columns=['image_id'])\ny_test = y_test.to_numpy()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-04T11:53:37.217266Z","iopub.execute_input":"2023-06-04T11:53:37.218475Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 75%|███████▍  | 1495/2000 [01:04<01:31,  5.54it/s] ","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\ndatagen.fit(x_train)\n\n# Define the EarlyStopping callback\nes_callback = EarlyStopping(monitor='val_loss', patience=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nbest_model = keras.models.load_model('/kaggle/input/best-model/isic2017.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the best model with augmented data\nhistory = best_model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_test, y_test), callbacks=[es_callback])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the best model on the test set\nscore = best_model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model.save('/kaggle/working/isic2017cnn1.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/working/test')\nos.mkdir('/kaggle/working/train')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_prob = model.predict(x_test)\ny_test = y_test.argmax(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:, 1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nauc = roc_auc_score(y_test, y_pred_prob[:, 1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(fpr)):\n    print(\"Threshold: {:.2f} | FPR: {:.4f} | TPR: {:.4f}\".format(thresholds[i], fpr[i], tpr[i]))\n\nprint(\"AUC: {:.4f}\".format(auc))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the ROC curve\nplt.plot(fpr, tpr, label='ROC curve (area = {:.4f})'.format(auc))\nplt.plot([0, 1], [0, 1], 'k--', label='Random guess')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='lower right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = y_pred_prob.argmax(axis=1)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming y_test and y_pred are the true and predicted labels, respectively\ncm = confusion_matrix(y_test, y_pred)\n\n# Print the confusion matrix\nprint(\"Confusion matrix:\")\nprint(cm)\n\n# Extract metrics from the confusion matrix\ntn, fp, fn, tp = cm.ravel()\n\n# Compute precision, recall, and F1-score\nprecision = tp / (tp + fp)\nrecall = tp / (tp + fn)\nf1_score = 2 * precision * recall / (precision + recall)\n\n# Print the metrics\nprint(\"Precision: {:.4f}\".format(precision))\nprint(\"Recall: {:.4f}\".format(recall))\nprint(\"F1-score: {:.4f}\".format(f1_score))\n\n# Generate a classification report\nprint(\"Classification report:\")\nprint(classification_report(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision = tp / (tp + fp)\nrecall = tp / (tp + fn)\nf1_score = 2 * precision * recall / (precision + recall)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\n\n# Assuming y_test and y_pred are the true and predicted labels, respectively\ncm = confusion_matrix(y_test, y_pred)\n\n# Define the names of the classes\nclasses = ['Class 0', 'Class 1']\n\n# Plot the confusion matrix\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.colorbar()\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.xticks(np.arange(len(classes)), classes)\nplt.yticks(np.arange(len(classes)), classes)\n\n# Add values to the plot\nthresh = cm.max() / 2.\nfor i, j in np.ndindex(cm.shape):\n    plt.text(j, i, format(cm[i, j], 'd'),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\n# Save the image\nplt.savefig('confusion_matrix.png')\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport numpy as np\n\n# Assuming y_test and y_pred are the true and predicted labels, respectively\ncm = confusion_matrix(y_test, y_pred)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Calculate accuracy for each class\nclass_accuracy = cm.diagonal() / cm.sum(axis=1)\n\n# Plot bar chart of accuracy for each class\nfig, ax = plt.subplots()\nax.bar(np.arange(len(classes)), class_accuracy)\nax.set_xticks(np.arange(len(classes)))\nax.set_xticklabels(classes)\n\n# Add accuracy value as text on top of each bar\nfor i, v in enumerate(class_accuracy):\n    ax.text(i, v+0.01, f'{v:.2f}', ha='center')\n\n# Set plot title and axis labels\nax.set_title('Accuracy for Each Class')\nax.set_xlabel('Class')\nax.set_ylabel('Accuracy')\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ny_pred = best_model.predict(x_test)\n\n# Print the actual and predicted data side by side\nfor i in range(len(y_test)):\n    print('Actual:', y_test[i],'Predicted:', y_pred[i])\n\n# Plot the training and validation loss and accuracy\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model architecture with hyperparameters\ndef build_model(hp):\n    model = Sequential()\n    model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=16, max_value=64, step=16),\n                     kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n                     activation='relu',\n                     input_shape=x_train[0].shape))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(2, 2))\n    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n\n    model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=128, step=32),\n                     kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n                     activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(2, 2))\n    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n\n    model.add(Flatten())\n    model.add(Dense(units=hp.Int('dense_1_units', min_value=64, max_value=256, step=64),\n                    activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(rate=hp.Float('dropout_3', min_value=0.1, max_value=0.5, step=0.1)))\n\n    model.add(Dense(2, activation='sigmoid'))\n\n    model.compile(optimizer=keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    return model\n\n# Hyperparameter tuning\ntuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    executions_per_trial=3,\n    directory='output',\n    project_name='ISIC')\n\ntuner.search_space_summary()\n\n# Perform the search for the best hyperparameters\ntuner.search(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n\n# Get the best model and hyperparameters\nbest_model = tuner.get_best_models(num_models=1)[0]\nbest_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the best model to a file\nbest_model.save('/kaggle/working/best_model.h5')\n\n# Save the best hyperparameters to a JSON file\nimport json\nwith open('/kaggle/working/best_hyperparameters.json', 'w') as f:\n    json.dump(best_hyperparameters.values, f)","metadata":{},"execution_count":null,"outputs":[]}]}